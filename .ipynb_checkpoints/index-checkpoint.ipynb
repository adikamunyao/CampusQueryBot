{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "200dbdca-af9b-4aa5-817b-55438179b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import requests\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from openai.embeddings_utils import get_embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cd262896-0b63-4ef3-8c96-4496444f1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79fee919-0fb3-4c10-b103-115b9b4d20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from(url):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    return '\\n'.join(line for line in lines if line)\n",
    "\n",
    "def fetch_sitemap(url):\n",
    "    r = requests.get(url)\n",
    "    xml = r.text\n",
    "    raw = xmltodict.parse(xml)\n",
    "    return raw\n",
    "\n",
    "def get_relevant_pages(sitemap, keyword):\n",
    "    pages = []\n",
    "    for info in sitemap['urlset']['url']:\n",
    "        url = info['loc']\n",
    "        if keyword in url:\n",
    "            pages.append({'text': extract_text_from(url), 'source': url})\n",
    "    return pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4460799b-1ada-4d65-9015-0853ccaf50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "sitemap_url = \"https://www.rgu.ac.uk/index.php?option=com_jmap&view=sitemap&format=xml\"\n",
    "sitemap = fetch_sitemap(sitemap_url)\n",
    "pages = get_relevant_pages(sitemap, 'international-students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ef4cc439-986d-4b1f-b24e-957a2dfc9bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "10e0ffe8-1537-48a7-ba54-deabf9bf85ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(pages):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1500, separator=\"\\n\")\n",
    "    docs, metadatas = [], []\n",
    "    for page in pages:\n",
    "        splits = text_splitter.split_text(page['text'])\n",
    "        docs.extend(splits)\n",
    "        metadatas.extend([{\"source\": page['source']}] * len(splits))\n",
    "    return docs, metadatas\n",
    "\n",
    "# Example usage\n",
    "docs, metadatas = preprocess_text(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0f0a500c-a221-4ff7-892d-f06545543959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e605e85b-b434-451c-a04d-5be3afcd1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(docs):\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    return [model.encode(doc) for doc in docs]\n",
    "\n",
    "# call function\n",
    "embeddings = generate_embeddings(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b3100352-1552-4a68-abb5-15ce4ce4cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = {\"documents\": docs, \"embeddings\": embeddings, \"metadatas\": metadatas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "30cf285a-6487-40a2-ab62-6451e16d7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def generate_embeddings(docs):\n",
    "    return [model.encode(doc) for doc in docs]\n",
    "\n",
    "def generate_query_embedding(query):\n",
    "    return model.encode(query)\n",
    "\n",
    "def find_similar(query, vector_store, model, top_n=5):\n",
    "    try:\n",
    "        # Ensure necessary keys are present in vector_store\n",
    "        if not all(key in vector_store for key in ['documents', 'embeddings', 'metadatas']):\n",
    "            raise ValueError(\"Vector store must contain 'documents', 'embeddings', and 'metadatas' keys.\")\n",
    "\n",
    "        # Encode the query\n",
    "        query_embedding = generate_query_embedding(query)\n",
    "        \n",
    "        # Ensure embeddings are of the same dimension\n",
    "        assert len(query_embedding) == len(vector_store['embeddings'][0]), \"Embedding dimensions do not match.\"\n",
    "        \n",
    "        # Compute similarity\n",
    "        similarities = cosine_similarity([query_embedding], vector_store['embeddings'])[0]\n",
    "        \n",
    "        # Get indices of the top N most similar documents\n",
    "        similar_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "        \n",
    "        # Collect the most similar documents, their metadata, and similarity scores\n",
    "        similar_docs = [\n",
    "            vector_store['documents'][i] for i in similar_indices\n",
    "        ]\n",
    "        \n",
    "        return similar_docs\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_answer_gpt4(relevant_documents, question):\n",
    "    # Combine relevant documents into a single context\n",
    "    context = \"\\n\\n\".join(relevant_documents)\n",
    "    \n",
    "    # Create a prompt for OpenAI\n",
    "    prompt = f\"Based on the following documents, answer the question:\\n\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    \n",
    "    # Generate the response from OpenAI using the chat endpoint\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message['content'].strip()\n",
    "\n",
    "\n",
    "def answer_question(query, vector_store, model, top_n=1):\n",
    "    # Find similar documents\n",
    "    similar_docs = find_similar(query, vector_store, model, top_n)\n",
    "    \n",
    "    # Generate and return an answer\n",
    "    answer = generate_answer_gpt4(similar_docs, query)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "28621638-f4f1-4b3f-be03-d8abf81f5078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "International students applying for a Graduate visa in the UK do not have to meet specific financial requirements or demonstrate a certain amount of money, nor do they need to provide evidence of English language proficiency, as these were already satisfied during their previous Tier 4 or Student visa application. Additionally, after the initial 2-year period on the Graduate visa, students have the option to switch to a Skilled Worker visa if they secure a job that meets the necessary criteria for that visa category.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"What are the visa requirements for international students?\"\n",
    "\n",
    "# Get the answer\n",
    "answer = answer_question(query, vector_store, model)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d2bea2e6-8c1f-490b-80fa-c19c2834891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#    while True:\n",
    "#         # Prompt user for input\n",
    "#         query = input(\"Enter your query (or type 'exit' to quit): \")\n",
    "        \n",
    "#         if query.lower() == 'exit':\n",
    "#             print(\"Exiting the program.\")\n",
    "#             break\n",
    "        \n",
    "#         # Get the answer\n",
    "#         answer = answer_question(query, vector_store, model)\n",
    "#         print(f\"Answer: {answer}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42398bc4-9ca3-43dc-a1af-368dc712ac27",
   "metadata": {},
   "source": [
    "### RGU CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "23a130ae-41ad-44c9-a151-19c3a77ee213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "def generate_embeddings(docs):\n",
    "    return [model.encode(doc) for doc in docs]\n",
    "\n",
    "def generate_query_embedding(query):\n",
    "    return model.encode(query)\n",
    "\n",
    "def find_similar(query, vector_store, model, top_n=1):\n",
    "    try:\n",
    "        # Ensure necessary keys are present in vector_store\n",
    "        if not all(key in vector_store for key in ['documents', 'embeddings', 'metadatas']):\n",
    "            raise ValueError(\"Vector store must contain 'documents', 'embeddings', and 'metadatas' keys.\")\n",
    "\n",
    "        # Encode the query\n",
    "        query_embedding = generate_query_embedding(query)\n",
    "        \n",
    "        # Ensure embeddings are of the same dimension\n",
    "        assert len(query_embedding) == len(vector_store['embeddings'][0]), \"Embedding dimensions do not match.\"\n",
    "        \n",
    "        # Compute similarity\n",
    "        similarities = cosine_similarity([query_embedding], vector_store['embeddings'])[0]\n",
    "        \n",
    "        # Get indices of the top N most similar documents\n",
    "        similar_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "        \n",
    "        # Collect the most similar documents\n",
    "        similar_docs = [\n",
    "            vector_store['documents'][i] for i in similar_indices\n",
    "        ]\n",
    "        \n",
    "        return similar_docs\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_answer_gpt4(relevant_documents, question):\n",
    "    # Combine relevant documents into a single context\n",
    "    context = \"\\n\\n\".join(relevant_documents)\n",
    "    \n",
    "    # Create a prompt for OpenAI\n",
    "    prompt = f\"Based on the following documents, answer the question:\\n\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    \n",
    "    # Generate the response from OpenAI using the chat endpoint\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",  # Using the chat model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message['content'].strip()\n",
    "\n",
    "def answer_question(query, vector_store, model, top_n=1):\n",
    "    # Define custom responses for specific queries\n",
    "    greetings = [\"hello\", \"hi\", \"greetings\", \"hey\", \"welcome\"]\n",
    "    if any(greeting in query.lower() for greeting in greetings):\n",
    "        return \"Welcome to Robert Gordon University! How can I assist you today?\"\n",
    "\n",
    "    # Find similar documents\n",
    "    similar_docs = find_similar(query, vector_store, model, top_n)\n",
    "    \n",
    "    # Generate and return an answer\n",
    "    answer = generate_answer_gpt4(similar_docs, query)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8387e2a3-6547-4a7f-a4f0-1ebf833acb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Welcome to Robert Gordon University! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  hellooo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Welcome to Robert Gordon University! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Welcome to Robert Gordon University! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  whatsaup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: It seems like you're asking for a casual greeting or an informal update. If you're looking for information or have a specific question about the documents or related topics, feel free to ask!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  clear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: It seems that you have provided a prompt, but I need more context or specific documents to generate a relevant answer. Could you please provide additional details or clarify your question?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  sponsor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: A sponsor is an individual or entity that provides financial support for a person's course fees and living costs, particularly in the context of visa applications. This can include official financial sponsors such as the UK government, your national government, the British Council, international organizations, international companies, universities, and independent schools. To demonstrate sponsorship, you need a letter from the sponsor that includes your name, their contact details, the length of the sponsorship, and the amount of money they will contribute, or a statement confirming that all fees and costs will be covered. This letter must be dated within the last six months when applying for a visa.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "def main():    \n",
    "    while True:\n",
    "        # Prompt user for input\n",
    "        query = input(\"Enter your query (or type 'exit' to quit): \")\n",
    "        \n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Exiting the program.\")\n",
    "            break\n",
    "        \n",
    "        # Get the answer\n",
    "        answer = answer_question(query, vector_store, model)\n",
    "        print(f\"Answer: {answer}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6429e8-e487-4a40-a38e-783c4e802fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
